{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wsd_fine.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HRrgWvbRTPvg",
        "ftsTsaQDTByP",
        "YFZCrvKaSp8B",
        "hQ6iWyTYP7O8"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfrarJahin/WSD/blob/main/Wsd_fine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KOAVFGBNvsT"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqPeuLSrN1hc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTtfNG5NvPDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b09c5b21-07f8-4746-c7d2-37770964387a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WKj94zi9xkL"
      },
      "source": [
        "path = \"/content/drive/MyDrive/data9k.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UZ0abf2VCF5"
      },
      "source": [
        "!pip install BnVec\n",
        "# !git clone https://github.com/banglakit/bengali-stemmer.git\n",
        "# !python -m pip install --upgrade pip\n",
        "# %cd bengali-stemmer\n",
        "# !pip install flake8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsuzkmNaOLmx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Embedding\n",
        "from  keras . utils  import  to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D,Conv2D, MaxPooling1D, Embedding, Flatten\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "from keras.layers import Embedding\n",
        "\n",
        "\n",
        "from pandas import DataFrame\n",
        "# from BnVec import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxXjNJEur3jg"
      },
      "source": [
        "#Load Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WksuwzKOlsW"
      },
      "source": [
        "df = pd.read_csv(path)\n",
        "s=len(set(df['ambiguous_word']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0dTyLNn-KmY"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqA37D9l_sUr"
      },
      "source": [
        "text = list(df['Text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExF6j5BZUkzU"
      },
      "source": [
        "ambi_word = list(df['ambiguous_word'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO0P5ArQGpIz",
        "outputId": "16cc12d2-858a-46ae-9831-3a1c0a8fb8e2"
      },
      "source": [
        "type(ambi_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I0zoyyl6Eaad",
        "outputId": "f2a9d3f2-1e8f-4f3e-f280-1c888b0f7269"
      },
      "source": [
        "text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'মাথা হলো মানবদেহে বিদ্যমান সবচেয়ে ভারি অংশ। মাথা'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zzFmj9L0O7q"
      },
      "source": [
        "# from bengali_stemmer.rafikamal2014 import RafiStemmer\n",
        "# stemmer = RafiStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbLKcIHdGrBd"
      },
      "source": [
        "# from bengali_stemmer.rafikamal2014 import RafiStemmer\n",
        "# stemmer = RafiStemmer()\n",
        "# stemmer.stem_word('কাটতেছে')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9fO7sSqVCLv"
      },
      "source": [
        "# df2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dataset/fine_tuned_data.csv')\n",
        "stopwords = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Dataset/Stopwords.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5A2rtYgfBeo"
      },
      "source": [
        "# length_array2 = []\n",
        "# for entry in df['Text']:\n",
        "#   length_array2.append(len(entry))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA2e4_yoG31L"
      },
      "source": [
        "# length_array2 = np.array(length_array2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-PIZxVbWGyI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPlQA5xmEN9N"
      },
      "source": [
        "# df = df.drop(['Unnamed: 3'] , axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxeDa3OoVCAZ"
      },
      "source": [
        "set_stop = set(stopwords['words'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihXuLCmKuane"
      },
      "source": [
        "#Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajohes5UVB9U"
      },
      "source": [
        "def clean_punct(sentence):\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#|।|’|‘]', r'', sentence)\n",
        "    cleaned1 = re.sub(r'[.|,|(|)|\\|/]', r'', cleaned)\n",
        "    # cleaned = re.sub(r'[০|১|২|৩|৪|৫|৬|৭|৮|৯]', r'', cleaned1)\n",
        "    cleaned1 = re.sub(r'[-|=]', r' ', cleaned1)\n",
        "    return cleaned1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOmOeXsPWMgB"
      },
      "source": [
        "def pre_process(data):\n",
        "    i=0\n",
        "    str1=' '\n",
        "    final_string = []\n",
        "    final_words = []\n",
        "    all_negative_words = []\n",
        "    s=''\n",
        "\n",
        "    for sentence in data:\n",
        "        filtered_sentence = []\n",
        "        for w in str(sentence).split():\n",
        "            for cleaned_word in clean_punct(w).split():\n",
        "                if len(cleaned_word)>2:\n",
        "                    # print(cleaned_word)\n",
        "                    if((cleaned_word) not in set_stop):\n",
        "                        # s = stemmer.stem_word(cleaned_word)\n",
        "                        s = cleaned_word\n",
        "                        #print(s)\n",
        "                        if len(s)>2:\n",
        "                            final_words.append(s)\n",
        "                            filtered_sentence.append(s)\n",
        "                    else:\n",
        "                        continue\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        str1 = \" \".join(filtered_sentence)\n",
        "        final_string.append(str1)\n",
        "    return final_string\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWKjioSaVB1j"
      },
      "source": [
        "import re\n",
        "re.compile('<title>(.*)</title>')\n",
        "text = pre_process(df['Text'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NljXZGI4ZbHM",
        "outputId": "87f0cb58-a18f-45ad-863e-a85d68f06eed"
      },
      "source": [
        "# len(set(df['ambiguous_word']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxmqDbrrxzcn",
        "outputId": "568f7b5e-5996-42c0-f20b-421e0e01adaf"
      },
      "source": [
        "# type(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR2y1j-Qx2YA",
        "outputId": "d2391b1d-c4fc-424b-fb71-52ffd13c00d0"
      },
      "source": [
        "# type(ambi_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31iT2Y9362_K"
      },
      "source": [
        "for i in range(len(text)):\n",
        "\ttext[i] = str(text[i])\n",
        "\n",
        "for i in range(len(ambi_word)):\n",
        "\tambi_word[i] = str(ambi_word[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyPuLtIt69JK"
      },
      "source": [
        "for i in range(len(text)):\n",
        "   ambi_word "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uEhifdax2Q7",
        "outputId": "d8da3113-2cb8-4553-c801-c8305cbae418"
      },
      "source": [
        "# type(df['ambiguous_word'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFkrPSqiZepT"
      },
      "source": [
        "\n",
        "for i in range(len(text)):\n",
        "  text[i] = text[i] + df['ambiguous_word'][i]\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grMrFnfpRXcw"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8KUUESDREKq"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "# define 5 documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!']\n",
        "# create the tokenizer\n",
        "t = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uMvjy2Udo6b"
      },
      "source": [
        "def load_data(num_words, sequence_length, test_size=0.25, oov_token=None):\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "    num_classes=16\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    X = tokenizer.texts_to_sequences(texts)\n",
        "    X = np.array(X)\n",
        "    # pad sequences with 0's\n",
        "    X = pad_sequences(X, maxlen=sequence_length)\n",
        "    # split data to training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)\n",
        "    data = {}\n",
        "    data[\"X_train\"] = X_train\n",
        "    data[\"X_test\"]= X_test\n",
        "    # data[\"y_train\"] = y_train\n",
        "    # data[\"y_test\"] = y_test\n",
        "    data[\"tokenizer\"] = tokenizer\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZYjp8HYY7XL"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh892vntJ0Qu"
      },
      "source": [
        "\n",
        "def get_embedding_vectors(word_index, embedding_size=100):\n",
        "    \n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_size))\n",
        "    # with open(f\"kaggle/input/bangla-golve/bn_glove.{embedding_size}d.txt\", encoding=\"utf8\") as f:\n",
        "    with open(f\"/content/drive/MyDrive/Colab Notebooks/Dataset/bn_glove.{embedding_size}d.txt\", encoding=\"utf8\") as f:\n",
        "        for line in tqdm(f, \"Reading GloVe\"):\n",
        "            values = line.split()\n",
        "            # get the word as the first word in the line\n",
        "            word = values[0]\n",
        "            if word in word_index:\n",
        "                idx = word_index[word]\n",
        "                # get the vectors as the remaining values in the line\n",
        "                embedding_matrix[idx] = np.array(values[1:], dtype=\"float32\")\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4IgV6mkNNN_"
      },
      "source": [
        "vec = get_embedding_vectors(t.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVf37IeFTASz"
      },
      "source": [
        "embedding_vecor_length = 300\n",
        "model = Sequential()\n",
        "model.add(Embedding(14028, 100,  weights=[vec], input_length=100))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(16, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n16uY3T-aaIt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-zv3Hz-ZenU"
      },
      "source": [
        "history = model.fit(text, label, validation_split=0.25  ,epochs=10, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4OtCP0TYHk2"
      },
      "source": [
        "# define model\n",
        "\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights=[vec], input_length=4, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(33, activation='softmax'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2bOQSnc0kk0"
      },
      "source": [
        "#Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdY9Y5urv4xZ"
      },
      "source": [
        "pip install bnlp_toolkit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6HxeZBl-CgA"
      },
      "source": [
        "from bnlp import BasicTokenizer     \n",
        "\n",
        " #for text tokenization    \n",
        "basic_t = BasicTokenizer()\n",
        "raw_text = []\n",
        "for i in range(len(texts)):\n",
        "  tokens = basic_t.tokenize(texts[i])\n",
        "  raw_text.append(tokens)\n",
        "raw_text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZwakjqa3QgI"
      },
      "source": [
        "raw_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVSUb1Es3e87"
      },
      "source": [
        "text = pre_process(raw_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wmtux19va3i"
      },
      "source": [
        "#for ambiguous_word tokenization\n",
        "raw_ambi = []\n",
        "for i in range(len(ambi)):\n",
        "  tokens = basic_t.tokenize(ambi[i])\n",
        "  raw_ambi.append(tokens)\n",
        "raw_ambi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8gFXKVtGsbK"
      },
      "source": [
        "#for meaning tokenization\n",
        "raw_mean = []\n",
        "for i in range(len(label)):\n",
        "  tokens = basic_t.tokenize(label[i])\n",
        "  raw_mean.append(tokens)\n",
        "raw_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSx7r1wWCD00"
      },
      "source": [
        "#POS Tagging text only!\n",
        "from bnlp import POS\n",
        "\n",
        "bn_pos = POS()\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/bn_pos.pkl\"\n",
        "\n",
        "res = []\n",
        "for i in range(len(text)):\n",
        "  p = bn_pos.tag(model_path,text[i])\n",
        "  res.append(p)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJu7ni7xyGAs"
      },
      "source": [
        "# from bnlp import BengaliGlove\n",
        "\n",
        "# bng = BengaliGlove()\n",
        "# glove_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/bn_glove.100d.txt\"\n",
        "# word = \"গ্রাম\"\n",
        "# res = bng.closest_word(glove_path, word)\n",
        "# print(res)\n",
        "# vec = bng.word2vec(glove_path, word)\n",
        "# print(vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqIsoS7K0s21"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPmvPnsVVBy5"
      },
      "source": [
        "df['ambi_word']= raw_ambi\n",
        "df['sense']= raw_mean\n",
        "df['text']= raw_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHbCMiVAFRdq"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_6k_yl_FMvM"
      },
      "source": [
        "X= df.drop(['ambiguous_word','meaning','Text','sense'], axis=1)\n",
        "\n",
        "y = df['sense']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrbekdcSL0No"
      },
      "source": [
        "X.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mm39G8z0Pb6"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6-dBc7kvEDu"
      },
      "source": [
        "ambi_word = list(X['ambi_word'])\n",
        "text = list(X['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM65ouoQaiFN"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lzGE1XYaCF9"
      },
      "source": [
        "ambi_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUyGzlrbLgDN"
      },
      "source": [
        "#Count Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CIoPA_9KyGR"
      },
      "source": [
        "from pandas import DataFrame\n",
        "from BnVec import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "x_ambi = cv.fit_transform(ambi_word) # x is the word features\n",
        "x_ambi.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzw8vh87YfwO"
      },
      "source": [
        "print(cv.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r40Eu1RXL4VD"
      },
      "source": [
        "x_text = cv.fit_transform(text)\n",
        "x_text.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwMYWSnXL82a"
      },
      "source": [
        "x = np.concatenate((x_text, x_ambi), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Kfaip_alfN"
      },
      "source": [
        "y = df['meaning']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBshHfBcavhc"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDkPKXW0MhwE"
      },
      "source": [
        "macronum=sorted(set(y.astype(str)))\n",
        "macro_to_id = dict((note, number) for number, note in enumerate(macronum))\n",
        "\n",
        "def fun(i):\n",
        "    return macro_to_id[i]\n",
        "\n",
        "label=y.apply(fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiXjgyp9MpD7"
      },
      "source": [
        "y=label\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TekxHP9MzUQ"
      },
      "source": [
        "# with open('/content/drive/MyDrive/Colab Notebooks/Dataset/.txt', 'wb') as f:\n",
        "#     pickle.dump(y, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkLbRw9XMzJa"
      },
      "source": [
        "# with open('/content/drive/MyDrive/Colab Notebooks/Dataset/data.txt', 'rb') as f:\n",
        "#     x = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7pRmcSLgm32"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI6mPZKEBaTI"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLNA8RHMqQPI"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8H3nbkbqLnM"
      },
      "source": [
        "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5As385ibqB8w"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U_llJjQqHiX"
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG-5NvIVqd7A"
      },
      "source": [
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpCaM-dFKXu-"
      },
      "source": [
        "svm_pred = clf.predict(X_test)\n",
        "svm_acc = accuracy_score(y_test, svm_pred, normalize=True) * float(100)\n",
        "\n",
        "print('SVM Accuracy %d%%' % (svm_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDN3C9f0qwVj"
      },
      "source": [
        "# from sklearn.model_selection import cross_val_score\n",
        "# clf = svm.SVC(kernel='linear', C=1)\n",
        "# scores = cross_val_score(clf, x, y, cv=5)\n",
        "# scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaJAuAsY-uuj"
      },
      "source": [
        "# from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kFH9-d9TP5K"
      },
      "source": [
        "# print(confusion_matrix(y_cv,svm_pred))\n",
        "# print(classification_report(y_cv,svm_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGs3nBYWZIr_"
      },
      "source": [
        "##KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PgHxEbzZMyy"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Kt_78jZTSr"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4jxDNOpaaIM"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # for data visualization purposes\n",
        "import seaborn as sns # for data visualization\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6siqoVSUZTHK"
      },
      "source": [
        "# import KNeighbors ClaSSifier from sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# instantiate the model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIP6KLRbZS7Z"
      },
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjPIxDlKZSlD"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Z7mUOWbVOm"
      },
      "source": [
        "y_pred_train = knn.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32q_gWx3bYgm"
      },
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9rXPbXThKuM"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwjGcONyg5EL"
      },
      "source": [
        "# experimenting with different n values\n",
        "k_range = list(range(1,26))\n",
        "scores = []\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    scores.append(metrics.accuracy_score(y_test, y_pred))\n",
        "    \n",
        "plt.plot(k_range, scores)\n",
        "plt.xlabel('Value of k for KNN')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Accuracy Scores for Values of k of k-Nearest-Neighbors')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-aAwwUcNuQn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQZ2wzArbbVv"
      },
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(knn.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(knn.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdoot_nxbiua"
      },
      "source": [
        "# instantiate the model with k=5\n",
        "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "knn_5.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# predict on the test-set\n",
        "y_pred_5 = knn_5.predict(X_test)\n",
        "\n",
        "\n",
        "print('Model accuracy score with k=5 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tToVDoWnWCYH"
      },
      "source": [
        "#Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy6Cx4g4WAWE"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/Dataset/target.txt', 'rb') as f:\n",
        "    y = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BRKrCTYWdA0"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/Dataset/bn_pos.pkl', 'rb') as f:\n",
        "    pos = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIoo0td7hIX2"
      },
      "source": [
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74BF_2U0M23H"
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgEnnLWTOxc9"
      },
      "source": [
        "# check the shape of X_train and X_test\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34I76_lGPX3_"
      },
      "source": [
        "##Naive Bayes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL63-wj_OxYL"
      },
      "source": [
        "# train a Gaussian Naive Bayes classifier on the training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "\n",
        "#fit the model\n",
        "gnb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icNTrJZsOxSu"
      },
      "source": [
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "#y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcmsdN4HOxOv"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w47ddlm3OxLG"
      },
      "source": [
        "y_pred_train = gnb.predict(X_train)\n",
        "\n",
        "#y_pred_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abAW1zKZOxHu"
      },
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "677JOMPgOw92"
      },
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(gnb.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(gnb.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcjMJGAYOw36"
      },
      "source": [
        "# Applying 10-Fold Cross Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(gnb, X_train, y_train, cv = 10, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores:{}'.format(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjCxpoJvOwzx"
      },
      "source": [
        "# compute Average cross-validation score\n",
        "\n",
        "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tStufLqZyte"
      },
      "source": [
        "##KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUk5pAdnOwwT"
      },
      "source": [
        "# import KNeighbors ClaSSifier from sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSw--MvCOws-"
      },
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "#y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FCCU3vMOwp8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-r4mJcCOwmc"
      },
      "source": [
        "y_pred_train = knn.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dagP7AeHOwjM"
      },
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2gfxI6MaXVN"
      },
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(knn.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(knn.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgVvAzBOaXF6"
      },
      "source": [
        "# instantiate the model with k=5\n",
        "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "knn_5.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# predict on the test-set\n",
        "y_pred_5 = knn_5.predict(X_test)\n",
        "\n",
        "\n",
        "print('Model accuracy score with k=5 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jped_CopaW2A"
      },
      "source": [
        "\n",
        "# instantiate the model with k=7\n",
        "knn_7 = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "knn_7.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# predict on the test-set\n",
        "y_pred_7 = knn_7.predict(X_test)\n",
        "\n",
        "\n",
        "print('Model accuracy score with k=7 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_7)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrbS8-fSamWc"
      },
      "source": [
        "# Applying 10-Fold Cross Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(knn, X_train, y_train, cv = 10, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores:{}'.format(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbtXC1csamI-"
      },
      "source": [
        "# compute Average cross-validation score\n",
        "\n",
        "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs3o3D6fcXvD"
      },
      "source": [
        "##SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zd14JhkcZ1K"
      },
      "source": [
        "# import SVC classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# import metrics to compute accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# instantiate classifier with default hyperparameters\n",
        "svc=SVC() \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-mjq2RV3ICp"
      },
      "source": [
        "print('Training set score: {:.4f}'.format(svc.score(X_train, y_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgE56hqB4Rhi"
      },
      "source": [
        "# Applying 10-Fold Cross Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "s_scores = cross_val_score(linear_svc, X_train, y_train, cv = 10, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores:{}'.format(s_scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg2QTrbD4RW_"
      },
      "source": [
        "# compute Average cross-validation score\n",
        "\n",
        "print('Average cross-validation score: {:.4f}'.format(s_scores.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSgVyEiMcbAS"
      },
      "source": [
        "# instantiate classifier with linear kernel and C=1.0\n",
        "linear_svc=SVC(kernel='linear', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred_test=linear_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvhHVlUmeshw"
      },
      "source": [
        "# instantiate classifier with rbf kernel and C=100\n",
        "svc=SVC(C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pC75OzxesHf"
      },
      "source": [
        "# instantiate classifier with rbf kernel and C=1000\n",
        "svc=SVC(C=1000.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX1ssbrHca5T"
      },
      "source": [
        "# instantiate classifier with linear kernel and C=100.0\n",
        "linear_svc100=SVC(kernel='linear', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc100.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=linear_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzPAatgCcazs"
      },
      "source": [
        "# instantiate classifier with linear kernel and C=1000.0\n",
        "linear_svc1000=SVC(kernel='linear', C=1000.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc1000.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=linear_svc1000.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSRL7qTKcark"
      },
      "source": [
        "y_pred_train = linear_svc.predict(X_train)\n",
        "\n",
        "y_pred_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7xGEf0pcak5"
      },
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFPJzB7acae6"
      },
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnlbx2AcfEpO"
      },
      "source": [
        "# instantiate classifier with polynomial kernel and C=1.0\n",
        "poly_svc=SVC(kernel='poly', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "poly_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=poly_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhqL8fICfEbB"
      },
      "source": [
        "# instantiate classifier with polynomial kernel and C=100.0\n",
        "poly_svc100=SVC(kernel='poly', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "poly_svc100.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=poly_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHmn-VQqfObY"
      },
      "source": [
        "\n",
        "# instantiate classifier with sigmoid kernel and C=1.0\n",
        "sigmoid_svc=SVC(kernel='sigmoid', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "sigmoid_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=sigmoid_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8VAMmXcfOSm"
      },
      "source": [
        "# instantiate classifier with sigmoid kernel and C=100.0\n",
        "sigmoid_svc100=SVC(kernel='sigmoid', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "sigmoid_svc100.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=sigmoid_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2CZvY0OfOGz"
      },
      "source": [
        "# import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# import SVC classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# instantiate classifier with default hyperparameters with kernel=rbf, C=1.0 and gamma=auto\n",
        "svc=SVC() \n",
        "\n",
        "\n",
        "\n",
        "# declare parameters for hyperparameter tuning\n",
        "parameters = [ {'C':[1, 10, 100, 1000], 'kernel':['linear']},\n",
        "               {'C':[1, 10, 100, 1000], 'kernel':['rbf'], 'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
        "               {'C':[1, 10, 100, 1000], 'kernel':['poly'], 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05]} \n",
        "              ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator = svc,  \n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5,\n",
        "                           verbose=0)\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAJfWxGFfqEz"
      },
      "source": [
        "# examine the best model\n",
        "\n",
        "\n",
        "# best score achieved during the GridSearchCV\n",
        "print('GridSearch CV best score : {:.4f}\\n\\n'.format(grid_search.best_score_))\n",
        "\n",
        "\n",
        "# print parameters that give the best results\n",
        "print('Parameters that give the best results :','\\n\\n', (grid_search.best_params_))\n",
        "\n",
        "\n",
        "# print estimator that was chosen by the GridSearch\n",
        "print('\\n\\nEstimator that was chosen by the search :','\\n\\n', (grid_search.best_estimator_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-QH_RZMfp9v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azfCEV5pfp1i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9ltZMfmJj3v"
      },
      "source": [
        "# **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvnaXKleMvMM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8IYB7aSMvGH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(x,y,train_size=0.7,random_state= 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bgSIYzGG6Ct"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqoExJchdfG4"
      },
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHXKZHUCIcf6"
      },
      "source": [
        "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
        "cv=KFold(n_splits=5,random_state=None,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrU1GvJAIeUo"
      },
      "source": [
        "clf=GridSearchCV(gnb,grid,cv=cv,n_jobs=-1,scoring='f1_macro')\n",
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ftZIw3Jdba"
      },
      "source": [
        "estimator.get_params().keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU6lWX0NJyo8"
      },
      "source": [
        "#Predict the results\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9P_AqWdMwaJ"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3NCjMU1J9zi"
      },
      "source": [
        "#Check accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFFh-knJHSh2"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAEGbyZPHUio"
      },
      "source": [
        "precision_score(y_train, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfBc4U9nHUaf"
      },
      "source": [
        "recall_score(y_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjKIxxVvHURY"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_train, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03pLQgNJJ4YB"
      },
      "source": [
        "###Compare the train-set and test-set accuracy\n",
        "y_pred_train = gnb.predict(X_train)\n",
        "\n",
        "y_pred_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc_1a18hLFAF"
      },
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxxOT_vMKDll"
      },
      "source": [
        "##Check for overfitting and underfitting\n",
        "print('Training set score: {:.4f}'.format(gnb.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(gnb.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7T1datlaHOj"
      },
      "source": [
        "###Null Accuracy\n",
        "# check class distribution in test set\n",
        "\n",
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU1HFmKiaG6x"
      },
      "source": [
        "# check null accuracy score\n",
        "\n",
        "null_accuracy = (***/(***+***))\n",
        "\n",
        "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXl0P915xhyD"
      },
      "source": [
        "##Confusion Metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9kNtRveJyig"
      },
      "source": [
        "#Classification metrices\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF1h7C-wL-oN"
      },
      "source": [
        "# # visualize confusion matrix with seaborn heatmap\n",
        "\n",
        "# cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
        "#                                  index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "# sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0QsTibeItsN"
      },
      "source": [
        "# Applying 10-Fold Cross Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(gnb, X_train, y_train, cv = 10, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores:{}'.format(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnwIqx5ce4yR"
      },
      "source": [
        "scores = cross_val_score(gnb, x, y, cv = 10, scoring='accuracy')\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSsXm2enfONC"
      },
      "source": [
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwrJVuSQWToW"
      },
      "source": [
        "# compute Average cross-validation score\n",
        "\n",
        "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUGcexFqeJ1o"
      },
      "source": [
        "# Applying 10-Fold Cross Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "t_scores = cross_val_score(gnb, X_test, y_test, cv = 10, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores:{}'.format(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LzKbQLJhK8_"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(x, y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyhuLiMxh5Ci"
      },
      "source": [
        "plt.scatter(x[:, 0], x[:, 1], c=y, s=50, cmap='RdBu');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ-plCqfh-ZP"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6eXaKDiIha"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRrgWvbRTPvg"
      },
      "source": [
        "## Further evaluation with SVC base estimator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYy3r9FWTQ7v"
      },
      "source": [
        "# load required classifer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "# import Support Vector Classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import accuracy_score\n",
        "svc=SVC(probability=True, kernel='linear')\n",
        "\n",
        "\n",
        "# create adaboost classifer object\n",
        "abc =AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1, random_state=0)\n",
        "\n",
        "\n",
        "# train adaboost classifer\n",
        "model2 = abc.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# predict the response for test dataset\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "\n",
        "# calculate and print model accuracy\n",
        "print(\"Model Accuracy with SVC Base Estimator:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftsTsaQDTByP"
      },
      "source": [
        "##Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mmelWzuTD78"
      },
      "source": [
        "#import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# calculate and print model accuracy\n",
        "print(\"AdaBoost Classifier Model Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFZCrvKaSp8B"
      },
      "source": [
        "##**Adaboost Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsSo2GcCSqj3"
      },
      "source": [
        "# Import the AdaBoost classifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "# Create adaboost classifer object\n",
        "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1, random_state=0)\n",
        "\n",
        "# Train Adaboost Classifer\n",
        "model1 = abc.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = model1.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ6iWyTYP7O8"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyR2PkTJLrS-"
      },
      "source": [
        "def get_embedding_vectors(word_index, embedding_size=100):\n",
        "    \n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_size))\n",
        "    with open(f\"/content/drive/MyDrive/Colab Notebooks/Dataset/bn_glove.{embedding_size}d.txt\", encoding=\"utf8\") as f:\n",
        "        for line in tqdm(f, \"Reading GloVe\"):\n",
        "            values = line.split()\n",
        "            # get the word as the first word in the line\n",
        "            word = values[0]\n",
        "            if word in word_index:\n",
        "                idx = word_index[word]\n",
        "                # get the vectors as the remaining values in the line\n",
        "                embedding_matrix[idx] = np.array(values[1:], dtype=\"float32\")\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AJOOm7pL3lG"
      },
      "source": [
        "embedding_matrix = get_embedding_vectors(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylf6rqNDNpbo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Ms7UCLH2d5"
      },
      "source": [
        "embedding_vecor_length = 100\n",
        "MAX_NUM_WORDS = 8411\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NUM_WORDS, embedding_vecor_length,  weights=[embedding_matrix], input_length=max_sequence_length))\n",
        "model.add(LSTM(100))\n",
        "\n",
        "model.add(Dense(528, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jtJulSbH2aH"
      },
      "source": [
        "model.fit(x=train_x,y=train_y,batch_size=100,epochs=10,verbose=1,shuffle=True,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm906ij_H2Xc"
      },
      "source": [
        "def load_data(num_words, sequence_length, test_size=0.25, oov_token=None):\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "    num_classes=528\n",
        "    y = to_categorical(np.asarray(label), num_classes)\n",
        "   \n",
        "   \n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=1)\n",
        "    data = {}\n",
        "    data[\"X_train\"] = X_train\n",
        "    data[\"X_test\"]= X_test\n",
        "    data[\"y_train\"] = y_train\n",
        "    data[\"y_test\"] = y_test\n",
        "    data[\"tokenizer\"] = tokenizer\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EgwA7GH2S0"
      },
      "source": [
        "history = model.fit(df['X_train'], df['y_train'], validation_data=(df['X_test'], df['y_test']), epochs=10, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ViF4xOiH2Qt"
      },
      "source": [
        "def load_data(num_words, sequence_length, test_size=0.25, oov_token=None):\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "    num_classes=528\n",
        "    y = to_categorical(np.asarray(label), num_classes)\n",
        "   \n",
        "   \n",
        "   \n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    X = tokenizer.texts_to_sequences(corpus)\n",
        "    X = np.array(X)\n",
        "    X = pad_sequences(X, maxlen=sequence_length)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=1)\n",
        "    data = {}\n",
        "    data[\"X_train\"] = X_train\n",
        "    data[\"X_test\"]= X_test\n",
        "    data[\"y_train\"] = y_train\n",
        "    data[\"y_test\"] = y_test\n",
        "    data[\"tokenizer\"] = tokenizer\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}